{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PatchTST for the forecast of German Energy consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Import necessary code\n",
    "- See Nick's structure and write a similar notebook with similar sections.\n",
    "- Check in original PatchTST repo code where are the preds\n",
    "- check to see if I can just discard the first 56\n",
    "- run my model with my dataset and with regular dataset but discarding 56 outputs and see which is more accurate\n",
    "- If I can't find it, just run the model with my code, verify it works (how?) and stick to that way of windowing\n",
    "- Create new dataset class for the supermarket data (gap?)\n",
    "- Order everything in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "from deutschland import feiertage\n",
    "from deutschland.feiertage.api import default_api\n",
    "configuration = feiertage.Configuration(\n",
    "    host = \"https://feiertage-api.de/api\"\n",
    ")\n",
    "\n",
    "import PatchTST\n",
    "from utils.tools import EarlyStopping, visual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with data loading later. For the time being, we use data already stored as .csv\n",
    "data_path = './dataset/'  # path to the data file\n",
    "root_path_name=data_path\n",
    "data_path_name='SMARD_converted.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath(data_path)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SMARD = pd.DataFrame()\n",
    "\n",
    "url=\"https://raw.githubusercontent.com/koljaeger/smardcast/main/data/Realisierter_Stromverbrauch_\"\n",
    "\n",
    "for year in range(2015, 2023+1, 1):\n",
    "    df_SMARD = pd.concat([df_SMARD, pd.read_csv(url+str(year)+\"01010000_\"+str(year)+\"12312359_Viertelstunde.csv\", \n",
    "                                    delimiter=\";\", thousands='.', decimal=\",\", dtype={\"Datum\":str})], axis=0, ignore_index=True)\n",
    "    \n",
    "df_SMARD[\"date\"] = pd.to_datetime(df_SMARD.pop(\"Datum\")+' '+df_SMARD.pop(\"Anfang\"), format=\"%d.%m.%Y %H:%M\")\n",
    "df_SMARD[\"date\"] = df_SMARD[\"date\"].dt.tz_localize(\"Europe/Berlin\", ambiguous='infer').dt.tz_convert('UTC')\n",
    "\n",
    "df_SMARD = df_SMARD.rename(\n",
    "        columns={\n",
    "        # 'Datum': \"date\", # expected by Dataset_Custom\n",
    "        'Gesamt (Netzlast) [MWh] Originalauflösungen': 'OT', # Grid load is target feature\n",
    "        'Residuallast [MWh] Originalauflösungen': 'Residual_load',\n",
    "        'Pumpspeicher [MWh] Originalauflösungen' : 'Pumped_storage'\n",
    "        }\n",
    "    )\n",
    "\n",
    "# \"Ende\" and \"Pumped_storage\" are not needed\n",
    "df_SMARD = df_SMARD.drop(columns=[\"Ende\", \"Pumped_storage\", \"Residual_load\"])\n",
    "\n",
    "# Add integer to indicate day of week \n",
    "df_SMARD[\"Weekday\"] = [n.day_of_week for n in df_SMARD[\"date\"]]\n",
    "\n",
    "# Add timestep functions\n",
    "minute = 60\n",
    "hour = 60*minute\n",
    "day = 24*hour\n",
    "week = 7*day\n",
    "year = (365.2425)*day\n",
    "month = year/12\n",
    "\n",
    "date_time = pd.to_datetime(df_SMARD[\"date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "df_SMARD['Hour sin'] = np.sin(timestamp_s * (2 * np.pi / hour))\n",
    "df_SMARD['Hour cos'] = np.cos(timestamp_s * (2 * np.pi / hour))\n",
    "df_SMARD['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df_SMARD['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df_SMARD['Week sin'] = np.sin(timestamp_s * (2 * np.pi / week))\n",
    "df_SMARD['Week cos'] = np.cos(timestamp_s * (2 * np.pi / week))\n",
    "df_SMARD['Month sin'] = np.sin(timestamp_s * (2 * np.pi / month))\n",
    "df_SMARD['Month cos'] = np.cos(timestamp_s * (2 * np.pi / month))\n",
    "df_SMARD['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df_SMARD['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "\n",
    "# Add holiday column\n",
    "# Assuming df[\"date\"] contains pandas datetime objects\n",
    "lowest_year = df_SMARD[\"date\"].dt.year.min()\n",
    "highest_year = df_SMARD[\"date\"].dt.year.max()\n",
    "\n",
    "holiday_dates = []\n",
    "\n",
    "with feiertage.ApiClient(configuration) as api_client:\n",
    "    api_instance = default_api.DefaultApi(api_client)\n",
    "\n",
    "for jahr in range(lowest_year, highest_year+1):\n",
    "    try:\n",
    "        api_response = api_instance.get_feiertage(jahr=str(jahr), nur_land=\"HH\", nur_daten=1)\n",
    "    except feiertage.ApiException as e:\n",
    "        print(\"Exception when calling DefaultApi->get_feiertage: %s\\n\" % e)\n",
    "\n",
    "    for feiertag in api_response:\n",
    "        holiday_dates.append(api_response[feiertag])\n",
    "\n",
    "df_SMARD[\"date\"] = pd.to_datetime(df_SMARD[\"date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "df_days = df_SMARD[\"date\"].dt.date\n",
    "\n",
    "# Calculate the days before holidays\n",
    "days_before_holidays = {date - datetime.timedelta(days=1) for date in holiday_dates}\n",
    "\n",
    "# Mark holidays and days before holidays in the DataFrame\n",
    "df_SMARD['Is Holiday'] = df_days.apply(lambda x: 1 if x in holiday_dates else (0.5 if x in days_before_holidays else 0))\n",
    "print(\"Holiday Signal Added!\")\n",
    "\n",
    "# Move 'OT' to the last position\n",
    "cols = [c for c in df_SMARD.columns if c != 'OT'] + ['OT']\n",
    "df_SMARD = df_SMARD[cols]\n",
    "\n",
    "df_SMARD.to_csv(data_path+data_path_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "PyTorch uses dataset and dataload classes to handle data for the model. In order to prepare for these classes, we load the data and store it as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "#PatchTST parameters\n",
    "seq_len=672 #Context window\n",
    "pred_len=96 #Forecast horizon\n",
    "patch_len=16\n",
    "stride=8\n",
    "#PatchTST defaults\n",
    "enc_in=1\n",
    "e_layers=3\n",
    "n_heads=16\n",
    "d_model=128\n",
    "d_ff=256\n",
    "dropout=0.2\n",
    "fc_dropout=0.2\n",
    "head_dropout=0\n",
    "individual_head=0 #True 1 False 0\n",
    "padding_patch='end' #end: padding on the end\n",
    "revin=1 # True 1 False 0\n",
    "affine=0 # True 1 False 0\n",
    "subtract_last=0 # 0: subtract mean; 1: subtract last\n",
    "decomposition=0 # decomposition; True 1 False 0\n",
    "kernel_size=25 \n",
    "scale = True\n",
    "\n",
    "dataset = 'SMARD_raw'\n",
    "\n",
    "# Training parameters\n",
    "batch_size=32 #default 128\n",
    "learning_rate=0.0001\n",
    "num_epochs=100\n",
    "label_len=0 #start token length | default 48 \n",
    "pct_start=0.3 # for cosine warmup\n",
    "patience = 20\n",
    "features='S' # 'S' single variable; 'MS' multivariate\n",
    "debugging=False\n",
    "if debugging:\n",
    "    num_epochs=2\n",
    "    batch_size=2\n",
    "    PatchTST.e_layers=1\n",
    "    PatchTST.d_model=8\n",
    "    PatchTST.d_ff=16\n",
    "    PatchTST.n_heads=2\n",
    "    num_workers=0\n",
    "else:\n",
    "    num_workers=10\n",
    "# drop_last=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "configs = Namespace(\n",
    "    enc_in=enc_in,\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    e_layers=e_layers,\n",
    "    n_heads=n_heads,\n",
    "    d_model=d_model,\n",
    "    d_ff=d_ff,\n",
    "    dropout=dropout,\n",
    "    fc_dropout=fc_dropout,\n",
    "    head_dropout=head_dropout,\n",
    "    individual=individual_head,\n",
    "    patch_len=patch_len,\n",
    "    stride=stride,\n",
    "    padding_patch=padding_patch,\n",
    "    revin=revin,\n",
    "    affine=affine,\n",
    "    subtract_last=subtract_last,\n",
    "    decomposition=decomposition,\n",
    "    kernel_size=kernel_size  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "setting = f'{data_path_name}_ft{features}_sl{seq_len}_ll{label_len}_pl{pred_len}_dm{d_model}_nh{n_heads}_el{e_layers}_df{d_ff}_ds{dropout}_eb{batch_size}_lr{dataset}+sc{scale}+{datetime.today()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset_Custom, Dataset_SMARD\n",
    "\n",
    "# Load data\n",
    "train_data = Dataset_SMARD(root_path=root_path_name,\n",
    "                            data_path=data_path_name,\n",
    "                            flag='train',\n",
    "                            size=[seq_len, label_len, pred_len],\n",
    "                            features=features, \n",
    "                            target='OT',\n",
    "                            split_mode='fixed',\n",
    "                            scale=scale)\n",
    "\n",
    "val_data = Dataset_SMARD(root_path=root_path_name,\n",
    "                            data_path=data_path_name,\n",
    "                            flag='val',\n",
    "                            size=[seq_len, label_len, pred_len],\n",
    "                            features=features, \n",
    "                            target='OT',\n",
    "                            split_mode='fixed',\n",
    "                            scale=scale)\n",
    "\n",
    "test_data = Dataset_SMARD(root_path=root_path_name,\n",
    "                            data_path=data_path_name,\n",
    "                            flag='test',\n",
    "                            size=[seq_len, label_len, pred_len],\n",
    "                            features=features, \n",
    "                            target='OT',\n",
    "                            split_mode='fixed',\n",
    "                            scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, ## Should this be false?\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    seq_x, seq_y = test_data[i]\n",
    "    print(f\"Sample {i} — seq_x[0:3]:\\n\", seq_x[:3])\n",
    "    print(f\"Sample {i} — seq_y[0:3]:\\n\", seq_y[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(test_loader)\n",
    "example_batch = next(examples)\n",
    "print(f\"shape of this example: {example_batch[0].shape}\")\n",
    "print(f\"num of examples in each batch: {len(example_batch)}\")\n",
    "\n",
    "print(f\"num of batches: {len(examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model\n",
    "model = PatchTST.Model(configs).to(device)\n",
    "print(model)\n",
    "path = os.path.join('./checkpoints/', setting)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "train_steps = len(train_loader)\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer = optimizer,\n",
    "                                            steps_per_epoch = train_steps,\n",
    "                                            pct_start = pct_start,\n",
    "                                            epochs = num_epochs,\n",
    "                                            max_lr = learning_rate)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali(vali_loader, criterion):\n",
    "        total_loss = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float().to(device)\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                f_dim = -1 if features == 'MS' else 0\n",
    "                outputs = outputs[:, -pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        model.train()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    iter_count = 0\n",
    "    train_loss = []\n",
    "    time_now = time.time()\n",
    "    model.train()\n",
    "    epoch_time = time.time()\n",
    "    for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        iter_count += 1\n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "    \n",
    "        outputs = model(batch_x)\n",
    "        # print(outputs.shape,batch_y.shape)\n",
    "        f_dim = -1 if features == 'MS' else 0\n",
    "        outputs = outputs[:, -pred_len:, f_dim:]\n",
    "        batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "            speed = (time.time() - time_now) / iter_count\n",
    "            left_time = speed * ((num_epochs - epoch) * train_steps - i)\n",
    "            print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "            iter_count = 0\n",
    "            time_now = time.time()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        #Adjust learning rate\n",
    "        lr_adjust = {epoch: scheduler.get_last_lr()[0]}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            if False: print('Updating learning rate to {}'.format(lr))\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "    train_loss = np.average(train_loss)\n",
    "    vali_loss = vali(val_loader, criterion)\n",
    "    test_loss = vali(test_loader, criterion)\n",
    "\n",
    "    print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "        epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "    early_stopping(vali_loss, model, path)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "from utils.metrics import metric\n",
    "\n",
    "best_model_path = path + '/' + 'checkpoint.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "def test(loader):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    inputx = []\n",
    "    mode = 'test' if loader == test_loader else 'val'\n",
    "\n",
    "    folder_path = './test_results/' + setting + '/' + mode + '/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            # print(outputs.shape,batch_y.shape)\n",
    "            # print(f\"outputs \\n {outputs}, batch_y (labels?) \\n {batch_y}\")\n",
    "            outputs = outputs[:, -pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "            pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
    "            true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
    "\n",
    "            \n",
    "\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "            inputx.append(batch_x.detach().cpu().numpy())\n",
    "            if i % 20 == 0:\n",
    "                input = batch_x.detach().cpu().numpy()\n",
    "                gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)\n",
    "    inputx = np.array(inputx)\n",
    "\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "    inputx = inputx.reshape(-1, inputx.shape[-2], inputx.shape[-1])\n",
    "\n",
    "    # result save\n",
    "    folder_path = './results/' + setting + '/' + mode + '/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # mae, mse, rmse, mape, mspe, rse, corr = metric(preds, trues)\n",
    "    # print('mse:{}, mae:{}, mape:{}'.format(mse, mae, mape))\n",
    "    # f = open(\"result.txt\", 'a')\n",
    "    # f.write(setting + \"  \\n\")\n",
    "    # f.write('mse:{}, mae:{}, mape:{}'.format(mse, mae, mape))\n",
    "    # f.write('\\n')\n",
    "    # f.write('\\n')\n",
    "    # f.close()\n",
    "\n",
    "    MAPE_val = (abs((trues - preds)/trues)*100)\n",
    "    print(f\"MAPE_val: {MAPE_val.mean()}\")\n",
    "\n",
    "    # np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe,rse, corr]))\n",
    "    np.save(folder_path + mode + 'pred.npy', preds)\n",
    "    np.save(folder_path + mode +'true.npy', trues)\n",
    "\n",
    "    return preds, trues, inputx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds, val_trues, val_inputx = test(val_loader)\n",
    "test_preds, test_trues, test_inputx = test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_preds.shape, val_trues.shape, val_inputx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_preds = val_preds.reshape(-1, val_preds.shape[-1])\n",
    "continuous_trues = val_trues.reshape(-1, val_trues.shape[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE = (abs((continuous_trues - continuous_preds)/continuous_trues)*100)\n",
    "print(f\"Validation MAPE: {MAPE.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_preds = test_preds.reshape(-1, test_preds.shape[-1])\n",
    "continuous_trues = test_preds.reshape(-1, test_preds.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE = (abs((continuous_trues - continuous_preds)/continuous_trues)*100)\n",
    "print(f\"Validation MAPE: {MAPE.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MAPE)\n",
    "print(continuous_trues)\n",
    "print(continuous_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_preds_inv = val_data.inverse_transform(val_preds)\n",
    "# val_trues_inv = val_data.inverse_transform(val_trues)\n",
    "# test_preds_inv = test_data.inverse_transform(test_preds)\n",
    "# test_trues_inv = test_data.inverse_transform(test_trues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "- Make sure MAPE calculation is correct\n",
    "- Ensure preds are preds \n",
    "- Do inverse transform\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patchtst_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
