{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PatchTST for the forecast of German Energy consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Import necessary code\n",
    "- See Nick's structure and write a similar notebook with similar sections.\n",
    "- Check in original PatchTST repo code where are the preds\n",
    "- check to see if I can just discard the first 56\n",
    "- run my model with my dataset and with regular dataset but discarding 56 outputs and see which is more accurate\n",
    "- If I can't find it, just run the model with my code, verify it works (how?) and stick to that way of windowing\n",
    "- Create new dataset class for the supermarket data (gap?)\n",
    "- Order everything in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import PatchTST\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "PyTorch uses dataset and dataload classes to handle data for the model. In order to prepare for these classes, we load the data and store it as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "#PatchTST parameters\n",
    "seq_len=672 #Context window\n",
    "pred_len=96 #Forecast horizon\n",
    "patch_len=16\n",
    "stride=8\n",
    "#PatchTST defaults\n",
    "enc_in=1\n",
    "e_layers=3\n",
    "n_heads=16\n",
    "d_model=128\n",
    "d_ff=256\n",
    "dropout=0.2\n",
    "fc_dropout=0.2\n",
    "head_dropout=0\n",
    "individual_head=0 #True 1 False 0\n",
    "padding_patch='end' #end: padding on the end\n",
    "revin=1 # True 1 False 0\n",
    "affine=0 # True 1 False 0\n",
    "subtract_last=0 # 0: subtract mean; 1: subtract last\n",
    "decomposition=0 # decomposition; True 1 False 0\n",
    "kernel_size=25 \n",
    "\n",
    "# Training parameters\n",
    "batch_size=32 #default 128\n",
    "learning_rate=0.0001\n",
    "num_epochs=100\n",
    "label_len=0 #start token length | default 48 \n",
    "pct_start=0.3 # for cosine warmup\n",
    "patience = 20\n",
    "features='S' # 'S' single variable; 'MS' multivariate\n",
    "debugging=True\n",
    "if debugging:\n",
    "    num_epochs=2\n",
    "    batch_size=2\n",
    "    PatchTST.e_layers=1\n",
    "    PatchTST.d_model=8\n",
    "    PatchTST.d_ff=16\n",
    "    PatchTST.n_heads=2\n",
    "    num_workers=0\n",
    "else:\n",
    "    num_workers=10\n",
    "# drop_last=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id_name='SMARD_PatchTST_seq' + str(seq_len) + '_pred' + str(pred_len)+'_patch'+str(patch_len)+'_stride'+str(stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "configs = Namespace(\n",
    "    enc_in=enc_in,\n",
    "    seq_len=seq_len,\n",
    "    pred_len=pred_len,\n",
    "    e_layers=e_layers,\n",
    "    n_heads=n_heads,\n",
    "    d_model=d_model,\n",
    "    d_ff=d_ff,\n",
    "    dropout=dropout,\n",
    "    fc_dropout=fc_dropout,\n",
    "    head_dropout=head_dropout,\n",
    "    individual=individual_head,\n",
    "    patch_len=patch_len,\n",
    "    stride=stride,\n",
    "    padding_patch=padding_patch,\n",
    "    revin=revin,\n",
    "    affine=affine,\n",
    "    subtract_last=subtract_last,\n",
    "    decomposition=decomposition,\n",
    "    kernel_size=kernel_size  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with data loading later. For the time being, we use data already stored as .csv\n",
    "data_path = '../experiments/PatchTST_supervised/dataset/'  # path to the data file\n",
    "root_path_name=data_path\n",
    "data_path_name='SMARD_converted.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = f'{data_path_name}_ft{features}_sl{seq_len}_ll{label_len}_pl{pred_len}_dm{d_model}_nh{n_heads}_el{e_layers}_df{d_ff}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset_Custom, Dataset_SMARD\n",
    "\n",
    "# Load data\n",
    "train_data = Dataset_SMARD(root_path=root_path_name,\n",
    "                            data_path=data_path_name,\n",
    "                            flag='train',\n",
    "                            size=[seq_len, label_len, pred_len],\n",
    "                            features=features, \n",
    "                            target='OT',\n",
    "                            split_mode='fixed')\n",
    "\n",
    "val_data = Dataset_SMARD(root_path=root_path_name,\n",
    "                            data_path=data_path_name,\n",
    "                            flag='val',\n",
    "                            size=[seq_len, label_len, pred_len],\n",
    "                            features=features, \n",
    "                            target='OT',\n",
    "                            split_mode='fixed')\n",
    "\n",
    "test_data = Dataset_SMARD(root_path=root_path_name,\n",
    "                            data_path=data_path_name,\n",
    "                            flag='test',\n",
    "                            size=[seq_len, label_len, pred_len],\n",
    "                            features=features, \n",
    "                            target='OT',\n",
    "                            split_mode='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, ## Should this be false?\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    seq_x, seq_y = test_data[i]\n",
    "    print(f\"Sample {i} — seq_x[0:3]:\\n\", seq_x[:3])\n",
    "    print(f\"Sample {i} — seq_y[0:3]:\\n\", seq_y[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(test_loader)\n",
    "example_batch = next(examples)\n",
    "print(f\"shape of this example: {example_batch[0].shape}\")\n",
    "print(f\"num of examples in each batch: {len(example_batch)}\")\n",
    "\n",
    "print(f\"num of batches: {len(examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# Initialize model\n",
    "model = PatchTST.Model(configs).to(device)\n",
    "print(model)\n",
    "path = os.path.join('./checkpoints/', setting)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "train_steps = len(train_loader)\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer = optimizer,\n",
    "                                            steps_per_epoch = train_steps,\n",
    "                                            pct_start = pct_start,\n",
    "                                            epochs = num_epochs,\n",
    "                                            max_lr = learning_rate)\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali(vali_loader, criterion):\n",
    "        total_loss = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "                # encoder - decoder\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                f_dim = -1 if features == 'MS' else 0\n",
    "                outputs = outputs[:, -pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        model.train()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    iter_count = 0\n",
    "    train_loss = []\n",
    "    time_now = time.time()\n",
    "    model.train()\n",
    "    epoch_time = time.time()\n",
    "    for i, (batch_x, batch_y, ) in enumerate(train_loader):\n",
    "        iter_count += 1\n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "        \n",
    "        # encoder - decoder\n",
    "    \n",
    "        outputs = model(batch_x)\n",
    "        # print(outputs.shape,batch_y.shape)\n",
    "        f_dim = -1 if features == 'MS' else 0\n",
    "        outputs = outputs[:, -pred_len:, f_dim:]\n",
    "        batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "            speed = (time.time() - time_now) / iter_count\n",
    "            left_time = speed * ((num_epochs - epoch) * train_steps - i)\n",
    "            print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "            iter_count = 0\n",
    "            time_now = time.time()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        #Adjust learning rate\n",
    "        lr_adjust = {epoch: scheduler.get_last_lr()[0]}\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            if False: print('Updating learning rate to {}'.format(lr))\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "    train_loss = np.average(train_loss)\n",
    "    vali_loss = vali(val_loader, criterion)\n",
    "    test_loss = vali(test_loader, criterion)\n",
    "\n",
    "    print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "        epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "    early_stopping(vali_loss, model, path)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))\n",
    "\n",
    "best_model_path = path + '/' + 'checkpoint.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patchtst_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
