{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import rand\n",
    "from argparse import Namespace\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "from deutschland import feiertage\n",
    "from deutschland.feiertage.api import default_api\n",
    "configuration = feiertage.Configuration(\n",
    "    host = \"https://feiertage-api.de/api\"\n",
    ")\n",
    "\n",
    "\n",
    "import PatchTST\n",
    "from utils.tools import EarlyStopping\n",
    "from datasets import Dataset_Custom, Dataset_SMARD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    SEED = seed\n",
    "    torch.manual_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_configs(enc_in=1, \n",
    "                seq_len = 672, \n",
    "                pred_len = 96, \n",
    "                e_layers = 3, \n",
    "                n_heads = 16, \n",
    "                d_model = 128, \n",
    "                d_ff = 256, \n",
    "                dropout = 0.2, \n",
    "                fc_dropout = 0.2,\n",
    "                head_dropout = 0,\n",
    "                individual_head = 0, \n",
    "                patch_len = 16, \n",
    "                stride = 8, \n",
    "                padding_patch = 'end', \n",
    "                revin = 1,  \n",
    "                affine = 0, \n",
    "                subtract_last = 0, \n",
    "                decomposition = 0, \n",
    "                kernel_size = 25,\n",
    "                label_len = 0,\n",
    "                features = 'S',\n",
    "                batch_size = 32,\n",
    "                learning_rate = 0.0001,\n",
    "                num_epochs = 100,\n",
    "                pct_start = 0.3,\n",
    "                patience = 20,\n",
    "                root_path_name='./dataset/',\n",
    "                data_path_name='SMARD_converted.csv',\n",
    "                num_workers=10\n",
    "                ):\n",
    "    configs = Namespace(\n",
    "        enc_in=enc_in,\n",
    "        seq_len=seq_len,\n",
    "        pred_len=pred_len,\n",
    "        e_layers=e_layers,\n",
    "        n_heads=n_heads,\n",
    "        d_model=d_model,\n",
    "        d_ff=d_ff,\n",
    "        dropout=dropout,\n",
    "        fc_dropout=fc_dropout,\n",
    "        head_dropout=head_dropout,\n",
    "        individual=individual_head,\n",
    "        patch_len=patch_len,\n",
    "        stride=stride,\n",
    "        padding_patch=padding_patch,\n",
    "        revin=revin,\n",
    "        affine=affine,\n",
    "        subtract_last=subtract_last,\n",
    "        decomposition=decomposition,\n",
    "        kernel_size=kernel_size,\n",
    "        label_len=label_len,\n",
    "        features = features,\n",
    "        batch_size = batch_size,\n",
    "        learning_rate = learning_rate,\n",
    "        num_epochs = num_epochs,\n",
    "        pct_start = pct_start,\n",
    "        patience = patience,\n",
    "        root_path_name=root_path_name,\n",
    "        data_path_name=data_path_name,\n",
    "        num_workers=num_workers  \n",
    "    )\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(configs):\n",
    "    train_data = Dataset_SMARD(root_path=configs.root_path_name,\n",
    "                                data_path=configs.data_path_name,\n",
    "                                flag='train',\n",
    "                                size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "                                features=configs.features, \n",
    "                                target='OT',\n",
    "                                split_mode='fixed',\n",
    "                                scale=True,\n",
    "                                window_split=1)\n",
    "\n",
    "    val_data = Dataset_SMARD(root_path=configs.root_path_name,\n",
    "                                data_path=configs.data_path_name,\n",
    "                                flag='val',\n",
    "                                size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "                                features=configs.features, \n",
    "                                target='OT',\n",
    "                                split_mode='fixed',\n",
    "                                scale=True)\n",
    "\n",
    "    test_data = Dataset_SMARD(root_path=configs.root_path_name,\n",
    "                                data_path=configs.data_path_name,\n",
    "                                flag='test',\n",
    "                                size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "                                features=configs.features, \n",
    "                                target='OT',\n",
    "                                split_mode='fixed',\n",
    "                                scale=True)\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_augmented_train_dataset(configs):\n",
    "    train_data = Dataset_SMARD(root_path=configs.root_path_name,\n",
    "                                data_path=configs.data_path_name,\n",
    "                                flag='train',\n",
    "                                size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "                                features=configs.features, \n",
    "                                target='OT',\n",
    "                                split_mode='fixed',\n",
    "                                scale=True)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(configs, train_data, val_data, test_data):\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "                train_data,\n",
    "                batch_size=configs.batch_size,\n",
    "                shuffle=True, ## Should this be false?\n",
    "                num_workers=configs.num_workers,\n",
    "                drop_last=True)\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "                val_data,\n",
    "                batch_size=configs.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=configs.num_workers,\n",
    "                drop_last=False)\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "                test_data,\n",
    "                batch_size=configs.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=configs.num_workers,\n",
    "                drop_last=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_shuffle_train_loader(configs, train_data):\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "                train_data,\n",
    "                batch_size=configs.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=configs.num_workers,\n",
    "                drop_last=True)\n",
    "\n",
    "        return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(configs, device, train_loader, seed):\n",
    "    model = PatchTST.Model(configs).to(device)\n",
    "    print(model)\n",
    "\n",
    "    # setting = f'ft{configs.features}_sl{configs.seq_len}_pl{configs.pred_len}_dm{configs.d_model}_nh{configs.n_heads}_el{configs.e_layers}_df{configs.d_ff}_ds{configs.dropout}_eb{configs.batch_size}_seed{seed}'\n",
    "    setting = f'ft{configs.features}_sl{configs.patch_len}_pl{configs.stride}_dm{configs.d_model}_nh{configs.n_heads}_el{configs.e_layers}_df{configs.d_ff}_ds{configs.dropout}_eb{configs.batch_size}_seed{seed}'\n",
    "\n",
    "\n",
    "    weights_path = os.path.join('./checkpoints/', setting)\n",
    "    if not os.path.exists(weights_path):\n",
    "        os.makedirs(weights_path)\n",
    "\n",
    "    train_steps = len(train_loader)\n",
    "    # Define loss function and optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=configs.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer = optimizer,\n",
    "                                                steps_per_epoch = train_steps,\n",
    "                                                pct_start = configs.pct_start,\n",
    "                                                epochs = configs.num_epochs,\n",
    "                                                max_lr = configs.learning_rate)\n",
    "    early_stopping = EarlyStopping(patience=configs.patience, verbose=True)\n",
    "    \n",
    "    return model, criterion, optimizer, scheduler, early_stopping, weights_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali(model, configs, device, val_loader, criterion):\n",
    "        total_loss = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y) in enumerate(val_loader):\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float().to(device)\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                f_dim = -1 if configs.features == 'MS' else 0\n",
    "                outputs = outputs[:, -configs.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -configs.pred_len:, f_dim:].to(device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        model.train()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, weights_path):\n",
    "\n",
    "    for epoch in range(configs.num_epochs):\n",
    "        iter_count = 0\n",
    "        train_loss = []\n",
    "        # time_now = time.time()\n",
    "        model.train()\n",
    "        epoch_time = time.time()\n",
    "        for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            iter_count += 1\n",
    "            optimizer.zero_grad()\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "        \n",
    "            outputs = model(batch_x)\n",
    "            f_dim = -1 if configs.features == 'MS' else 0\n",
    "            outputs = outputs[:, -configs.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -configs.pred_len:, f_dim:].to(device)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # if (i + 1) % 100 == 0:\n",
    "            #     print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "            #     speed = (time.time() - time_now) / iter_count\n",
    "            #     left_time = speed * ((configs.num_epochs - epoch) * configs.train_steps - i)\n",
    "            #     print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "            #     iter_count = 0\n",
    "            #     time_now = time.time()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            #Adjust learning rate\n",
    "            lr_adjust = {epoch: scheduler.get_last_lr()[0]}\n",
    "            if epoch in lr_adjust.keys():\n",
    "                lr = lr_adjust[epoch]\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr\n",
    "                # if False: print('Updating learning rate to {}'.format(lr))\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "        train_loss = np.average(train_loss)\n",
    "        val_loss = vali(model, configs, device, val_loader, criterion) \n",
    "        \n",
    "        early_stopping(val_loss, model, weights_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            test_loss = vali(model, configs, device, test_loader, criterion)\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "            epoch + 1, len(train_loader), train_loss, val_loss, test_loss))\n",
    "            break\n",
    "\n",
    "        print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(configs, model, loader, device):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    inputx = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "            f_dim = -1 if configs.features == 'MS' else 0\n",
    "            outputs = outputs[:, -configs.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -configs.pred_len:, f_dim:].to(device)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "            pred = outputs\n",
    "            true = batch_y\n",
    "\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "            inputx.append(batch_x.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    trues = np.concatenate(trues, axis=0)\n",
    "    inputx = np.concatenate(inputx, axis=0)\n",
    "\n",
    "    return preds, trues, inputx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_SMARD_prediction_data(path, remove_bad_columns=False):\n",
    "\n",
    "    df = pd.read_csv(path, delimiter=';', thousands='.', decimal=',', dtype={\"Datum\":str})\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df.pop(\"Datum\")+' '+df.pop(\"Anfang\"), format=\"%d.%m.%Y %H:%M\")\n",
    "    df[\"Date\"] = df[\"Date\"].dt.tz_localize(\"Europe/Berlin\", ambiguous='infer').dt.tz_convert('UTC')\n",
    "\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "        'Gesamt (Netzlast) [MWh] Originalauflösungen': 'Total Load [MWh]',\n",
    "        'Residuallast [MWh] Originalauflösungen': 'Residual Load [MWh]'\n",
    "        }\n",
    "    )\n",
    "    if remove_bad_columns==True:\n",
    "        df = df.drop(['Residual Load [MWh]'], axis=\"columns\")\n",
    "        df.pop('Ende')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_results(val_dates, test_dates, val_trues, test_trues, val_results, test_results):\n",
    "    # take dates, trues and preds\n",
    "    # create a dataframe for validation and another one for test results, \n",
    "    # the columns for each are the dates, trues and preds for each model\n",
    "    # retrieve SMARD data and merge with results dataframes\n",
    "    # concatenate both dataframes\n",
    "    all_val_results = pd.DataFrame({\n",
    "        \"Date\": pd.to_datetime(val_dates, format=\"ISO8601\"),\n",
    "        \"True Value\": val_trues\n",
    "    })\n",
    "    for i, val_pred in enumerate(val_results):\n",
    "        all_val_results[f\"Model {i+1} Forecast\"] = val_pred\n",
    "\n",
    "    for i, val_pred in enumerate(val_results):\n",
    "        all_val_results[f\"Model {i+1} Absolute Error\"] = np.abs(all_val_results[\"True Value\"] - all_val_results[f\"Model {i+1} Forecast\"])\n",
    "    \n",
    "    for i, val_pred in enumerate(val_results):\n",
    "        all_val_results[f\"Model {i+1} Absolute Percentage Error\"] = (abs(all_val_results[\"True Value\"] - all_val_results[f\"Model {i+1} Forecast\"])/all_val_results[\"True Value\"]*100)\n",
    "\n",
    "    all_test_results = pd.DataFrame({\n",
    "        \"Date\": pd.to_datetime(test_dates, format=\"ISO8601\"),\n",
    "        \"True Value\": test_trues\n",
    "    })\n",
    "\n",
    "    for i, test_pred in enumerate(test_results):\n",
    "        all_test_results[f\"Model {i+1} Forecast\"] = test_pred\n",
    "    \n",
    "    for i, test_pred in enumerate(test_results):\n",
    "        all_test_results[f\"Model {i+1} Absolute Error\"] = np.abs(all_test_results[\"True Value\"] - all_test_results[f\"Model {i+1} Forecast\"])\n",
    "    \n",
    "    for i, test_pred in enumerate(test_results):\n",
    "        all_test_results[f\"Model {i+1} Absolute Percentage Error\"] = (abs(all_test_results[\"True Value\"] - all_test_results[f\"Model {i+1} Forecast\"])/all_test_results[\"True Value\"]*100)\n",
    "    \n",
    "    display(all_val_results.describe())\n",
    "    display(all_test_results.describe())\n",
    "\n",
    "    url=\"https://raw.githubusercontent.com/koljaeger/smardcast/main/data/Prognostizierter_Stromverbrauch_\"\n",
    "\n",
    "    SMARD_prediction_df = pd.concat([read_SMARD_prediction_data(url+\"202101010000_202112312359_Viertelstunde.csv\", remove_bad_columns=True),\n",
    "                                    read_SMARD_prediction_data(url+\"202201010000_202212312359_Viertelstunde.csv\", remove_bad_columns=True),\n",
    "                                    read_SMARD_prediction_data(url+\"202301010000_202312312359_Viertelstunde.csv\", remove_bad_columns=True)])\n",
    "\n",
    "    all_val_results[\"SMARD Forecast\"] = list(SMARD_prediction_df[\"Total Load [MWh]\"][(SMARD_prediction_df[\"Date\"] >= all_val_results[\"Date\"].iloc[0]) & (all_val_results[\"Date\"].iloc[-1] >= SMARD_prediction_df[\"Date\"])])\n",
    "    all_test_results[\"SMARD Forecast\"] = list(SMARD_prediction_df[\"Total Load [MWh]\"][(SMARD_prediction_df[\"Date\"] >= all_test_results[\"Date\"].iloc[0]) & (all_test_results[\"Date\"].iloc[-1] >= SMARD_prediction_df[\"Date\"])])\n",
    "\n",
    "    results = pd.concat([all_val_results, all_test_results])\n",
    "    results[\"SMARD Absolute Error\"] = abs(results[\"True Value\"] - results[\"SMARD Forecast\"])\n",
    "\n",
    "    results[\"SMARD Absolute Percentage Error\"] = (abs(results[\"True Value\"] - results[\"SMARD Forecast\"])/results[\"True Value\"]*100)\n",
    "\n",
    "    results[\"Date\"] = pd.to_datetime(results[\"Date\"], format=\"%d.%m.%Y %H:%M\")\n",
    "    display(results.describe())\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_interval(train= True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [42] #remove after testing\n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    return ci, results, elapsed_times\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci, results, elapsed = get_confidence_interval()\n",
    "print(elapsed)\n",
    "np.save('elapsed_default.npy', np.array(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_interval_electricity_configs(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(enc_in=321, pct_start = 0.2, patience=10, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(enc_in=321, pct_start = 0.2, patience=10)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ci, e_results, e_elapsed = get_confidence_interval_electricity_configs()\n",
    "print(e_elapsed)\n",
    "np.save('e_elapsed.npy', np.array(e_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "np.array(e_elapsed)/60 = array([62.56247048, 46.16159238, 54.94956331])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def visualize_results(results):\n",
    "    results[\"Weekday\"] = results['Date'].dt.day_name().str.slice(0, 3)\n",
    "    order_days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    results['Weekday'] = pd.Categorical(results['Weekday'], categories=order_days, ordered=True)\n",
    "\n",
    "    weekday_mean_model_APE = results.groupby(['Weekday'], observed=True)[\"Model 2 Absolute Percentage Error\"].mean()\n",
    "    weekday_mean_SMARD_APE = results.groupby(['Weekday'], observed=True)[\"SMARD Absolute Percentage Error\"].mean()\n",
    "\n",
    "    mape_data = pd.DataFrame({\n",
    "        'Weekday': order_days,\n",
    "        'PatchTST': weekday_mean_model_APE,\n",
    "        'SMARD Forecast': weekday_mean_SMARD_APE\n",
    "    })\n",
    "\n",
    "\n",
    "    mape_data.plot(kind='bar', figsize=(20, 8), color=[\"orange\",\"red\",\"blue\"])\n",
    "\n",
    "    plt.xlabel('Day of the Week', fontsize = 15)\n",
    "    plt.ylabel('Mean Absolute Percentage Error (MAPE) [%]', fontsize = 15)\n",
    "    plt.xticks(rotation=0, fontsize = 15)\n",
    "    plt.yticks(fontsize = 15)\n",
    "    plt.legend(fontsize = 15)\n",
    "    plt.show()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(e_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_holiday_week(results):\n",
    "    fig1 = plt.figure(figsize=(20, 8))\n",
    "\n",
    "    results['Year Month Day'] = results['Date'].dt.strftime('%Y %m %d')\n",
    "\n",
    "    week_data = results[results['Year Month Day'].between('2022 10 02', '2022 10 08')]\n",
    "\n",
    "    plt.plot(week_data['Date'], week_data['True Value'], color='black', label='True Value')\n",
    "    plt.plot(week_data['Date'], week_data['Model 2 Forecast'], color='orange', label='PatchTST')\n",
    "    plt.plot(week_data['Date'], week_data['SMARD Forecast'], color='red', label='SMARD')\n",
    "    plt.xlabel('Datum', fontsize = 15)\n",
    "    plt.ylabel('Gesamt (Netzlast) [MWh]', fontsize = 15)\n",
    "    plt.ylim(9000, 19000)\n",
    "    plt.tick_params(axis='both', labelsize = 15)\n",
    "\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d.%m.%y'))\n",
    "    plt.legend(fontsize = 15, loc='upper right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_holiday_week(e_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_interval_default_configs_M(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(features='M', num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(features='M')\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_M, results_M, elapsed_M = get_confidence_interval_default_configs_M()\n",
    "print(elapsed_M)\n",
    "np.save('elapsed_times_default_M.npy', np.array(elapsed_M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(elapsed_M)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_not_augmented(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_data = get_non_augmented_train_dataset(configs)\n",
    "\n",
    "    _ , val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        weights_path = os.path.join(path, '_not_augmented/')\n",
    "        if not os.path.exists(weights_path):\n",
    "            os.makedirs(weights_path)\n",
    "\n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, weights_path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.weights_path.join(weights_path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_na, results_na, elapsed_na = get_ci_not_augmented()\n",
    "print(elapsed_na)\n",
    "np.save('elapsed_na.npy', np.array(elapsed_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_32_patches_S_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(enc_in=321, pct_start = 0.2, patience=10, patch_len=72, stride=20, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(enc_in=321, pct_start = 0.2, patience=10, patch_len=72, stride=20)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_32, results_32, elapsed_32 = get_ci_32_patches_S_e()\n",
    "print(elapsed_32)\n",
    "np.save('elapsed_32.npy', np.array(elapsed_32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_64_patches_S_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(enc_in=321, pct_start = 0.2, patience=10, patch_len=52, stride=10, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(enc_in=321, pct_start = 0.2, patience=10, patch_len=52, stride=10)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_64, results_64, elapsed_64 = get_ci_64_patches_S_e()\n",
    "print(elapsed_64)\n",
    "np.save('elapsed_64.npy', np.array(elapsed_64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_1_head_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(n_heads = 1, enc_in=321, pct_start = 0.2, patience=10, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(n_heads = 1, enc_in=321, pct_start = 0.2, patience=10)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_1_head, results_1_head, elapsed_1_head = get_ci_1_head_e()\n",
    "print(elapsed_1_head)\n",
    "np.save('elapsed_1_head.npy', np.array(elapsed_1_head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_8_heads_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(n_heads = 8, enc_in=321, pct_start = 0.2, patience=10, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(n_heads = 8, enc_in=321, pct_start = 0.2, patience=10)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_8_heads, results_8_heads, elapsed_8_heads = get_ci_8_heads_e()\n",
    "print(elapsed_8_heads)\n",
    "np.save('elapsed_8_heads.npy', np.array(elapsed_8_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_32_heads_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(n_heads = 32, enc_in=321, pct_start = 0.2, patience=10, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(n_heads = 32, enc_in=321, pct_start = 0.2, patience=10)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_32_heads, results_32_heads, elapsed_32_heads = get_ci_32_heads_e()\n",
    "print(elapsed_32_heads)\n",
    "np.save('elapsed_32_heads.npy', np.array(elapsed_32_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_no_train_shuffle_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(n_heads = 32, enc_in=321, pct_start = 0.2, patience=10, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(n_heads = 32, enc_in=321, pct_start = 0.2, patience=10)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader = get_no_shuffle_train_loader(configs, train_data)\n",
    "    _ , val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    # random_seeds = [987654, 202411, 7777777] \n",
    "    # for i in range(5):\n",
    "    #     random_seed = rand.randint(0, 10000)\n",
    "    #     random_seeds.append(random_seed)\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    # val_trues = []\n",
    "    # test_trues = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        weights_path = os.path.join(path, '_not_augmented/')\n",
    "        if not os.path.exists(weights_path):\n",
    "            os.makedirs(weights_path)\n",
    "\n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, weights_path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(weights_path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_no_shuffle, results_no_shuffle, elapsed_no_shuffle = get_ci_no_train_shuffle_e()\n",
    "print(elapsed_no_shuffle)\n",
    "np.save('elapsed_no_shuffle.npy', np.array(elapsed_no_shuffle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_patch_len_2_stride_1_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(n_heads = 32, enc_in=321, pct_start = 0.2, patience=10, patch_len=2, stride=1, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(n_heads = 32, enc_in=321, pct_start = 0.2, patience=10, patch_len=2, stride=1)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_l2_s1, results_l2_s1, elapsed_l2_s1 = get_ci_patch_len_2_stride_1_e()\n",
    "print(elapsed_l2_s1)\n",
    "np.save('elapsed_l2_s1.npy', np.array(elapsed_l2_s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_patch_len_1_stride_1_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(n_heads = 32, enc_in=321, pct_start = 0.2, patience=10, patch_len=1, stride=1, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(n_heads = 32, enc_in=321, pct_start = 0.2, patience=10, patch_len=1, stride=1)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_l1_s1, results_l1_s1, elapsed_l1_s1 = get_ci_patch_len_1_stride_1_e()\n",
    "print(elapsed_l1_s1)\n",
    "np.save('elapsed_l1_s1.npy', np.array(elapsed_l1_s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci_d_model_32_e(train=True, debug=False):\n",
    "\n",
    "    if debug:\n",
    "        configs = get_configs(d_model=32, enc_in=321, pct_start = 0.2, patience=10, num_workers=0)\n",
    "    else:\n",
    "        configs = get_configs(d_model=32, enc_in=321, pct_start = 0.2, patience=10)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        else:\n",
    "            #load weights\n",
    "            model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "    \n",
    "    return ci, results, elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_d_model_32_e, resultsd_model_32_e, elapsedd_model_32_e = get_ci_d_model_32_e()\n",
    "print(elapsedd_model_32_e)\n",
    "np.save('elapsed_model_dim_64.npy', np.array(print(elapsedd_model_32_e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patchtst_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
