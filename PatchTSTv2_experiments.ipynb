{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import rand\n",
    "from argparse import Namespace\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "from deutschland import feiertage\n",
    "from deutschland.feiertage.api import default_api\n",
    "configuration = feiertage.Configuration(\n",
    "    host = \"https://feiertage-api.de/api\"\n",
    ")\n",
    "\n",
    "import PatchTST\n",
    "from utils.tools import EarlyStopping\n",
    "from datasets import Dataset_Custom, Dataset_SMARD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    SEED = seed\n",
    "    torch.manual_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_configs(\n",
    "                name,\n",
    "                enc_in=1, \n",
    "                seq_len = 672, \n",
    "                pred_len = 96, \n",
    "                e_layers = 3, \n",
    "                n_heads = 16, \n",
    "                d_model = 128, \n",
    "                d_ff = 256, \n",
    "                dropout = 0.2, \n",
    "                fc_dropout = 0.2,\n",
    "                head_dropout = 0,\n",
    "                individual_head = 0, \n",
    "                patch_len = 16, \n",
    "                stride = 8, \n",
    "                padding_patch = 'end', \n",
    "                revin = 1,  \n",
    "                affine = 0, \n",
    "                subtract_last = 0, \n",
    "                decomposition = 0, \n",
    "                kernel_size = 25, # end of PatchTST params\n",
    "                label_len = 0,\n",
    "                features = 'S',\n",
    "                batch_size = 128,\n",
    "                learning_rate = 0.0001,\n",
    "                num_epochs = 100,\n",
    "                pct_start = 0.4, #for scheduler\n",
    "                patience = 20,\n",
    "                root_path_name='./dataset/',\n",
    "                data_path_name='SMARD_converted.csv',\n",
    "                num_workers=10,\n",
    "                window_split=1,\n",
    "                shuffle_train=True\n",
    "                ):\n",
    "    configs = Namespace(\n",
    "        name = name,\n",
    "        enc_in=enc_in,\n",
    "        seq_len=seq_len,\n",
    "        pred_len=pred_len,\n",
    "        e_layers=e_layers,\n",
    "        n_heads=n_heads,\n",
    "        d_model=d_model,\n",
    "        d_ff=d_ff,\n",
    "        dropout=dropout,\n",
    "        fc_dropout=fc_dropout,\n",
    "        head_dropout=head_dropout,\n",
    "        individual=individual_head,\n",
    "        patch_len=patch_len,\n",
    "        stride=stride,\n",
    "        padding_patch=padding_patch,\n",
    "        revin=revin,\n",
    "        affine=affine,\n",
    "        subtract_last=subtract_last,\n",
    "        decomposition=decomposition,\n",
    "        kernel_size=kernel_size,\n",
    "        label_len=label_len,\n",
    "        features = features,\n",
    "        batch_size = batch_size,\n",
    "        learning_rate = learning_rate,\n",
    "        num_epochs = num_epochs,\n",
    "        pct_start = pct_start,\n",
    "        patience = patience,\n",
    "        root_path_name=root_path_name,\n",
    "        data_path_name=data_path_name,\n",
    "        num_workers=num_workers,\n",
    "        window_split=window_split,\n",
    "        shuffle_train=shuffle_train\n",
    "    )\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(configs):\n",
    "    train_data = Dataset_SMARD(root_path=configs.root_path_name,\n",
    "                                data_path=configs.data_path_name,\n",
    "                                flag='train',\n",
    "                                size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "                                features=configs.features, \n",
    "                                target='OT',\n",
    "                                split_mode='fixed',\n",
    "                                scale=True,\n",
    "                                window_split=configs.window_split)\n",
    "\n",
    "    val_data = Dataset_SMARD(root_path=configs.root_path_name,\n",
    "                                data_path=configs.data_path_name,\n",
    "                                flag='val',\n",
    "                                size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "                                features=configs.features, \n",
    "                                target='OT',\n",
    "                                split_mode='fixed',\n",
    "                                scale=True)\n",
    "\n",
    "    test_data = Dataset_SMARD(root_path=configs.root_path_name,\n",
    "                                data_path=configs.data_path_name,\n",
    "                                flag='test',\n",
    "                                size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "                                features=configs.features, \n",
    "                                target='OT',\n",
    "                                split_mode='fixed',\n",
    "                                scale=True)\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_non_augmented_train_dataset(configs):\n",
    "#     train_data = Dataset_SMARD(root_path=configs.root_path_name,\n",
    "#                                 data_path=configs.data_path_name,\n",
    "#                                 flag='train',\n",
    "#                                 size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "#                                 features=configs.features, \n",
    "#                                 target='OT',\n",
    "#                                 split_mode='fixed',\n",
    "#                                 scale=True)\n",
    "    \n",
    "#     return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(configs, train_data, val_data, test_data):\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "                train_data,\n",
    "                batch_size=configs.batch_size,\n",
    "                shuffle=configs.shuffle_train, ## Should this be false?\n",
    "                num_workers=configs.num_workers,\n",
    "                drop_last=True)\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "                val_data,\n",
    "                batch_size=configs.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=configs.num_workers,\n",
    "                drop_last=False)\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "                test_data,\n",
    "                batch_size=configs.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=configs.num_workers,\n",
    "                drop_last=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_no_shuffle_train_loader(configs, train_data):\n",
    "\n",
    "#         train_loader = DataLoader(\n",
    "#                 train_data,\n",
    "#                 batch_size=configs.batch_size,\n",
    "#                 shuffle=False,\n",
    "#                 num_workers=configs.num_workers,\n",
    "#                 drop_last=True)\n",
    "\n",
    "#         return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(configs, device, train_loader, seed):\n",
    "    model = PatchTST.Model(configs).to(device)\n",
    "    print(model)\n",
    "\n",
    "    # setting = f'ft{configs.features}_sl{configs.seq_len}_pl{configs.pred_len}_dm{configs.d_model}_nh{configs.n_heads}_el{configs.e_layers}_df{configs.d_ff}_ds{configs.dropout}_eb{configs.batch_size}_seed{seed}'\n",
    "    # setting = f'ft{configs.features}_sl{configs.patch_len}_pl{configs.stride}_dm{configs.d_model}_nh{configs.n_heads}_el{configs.e_layers}_df{configs.d_ff}_ds{configs.dropout}_eb{configs.batch_size}_seed{seed}'\n",
    "    setting = f'{configs.name}ft{configs.features}_pl{configs.patch_len}_st{configs.stride}_dm{configs.d_model}_nh{configs.n_heads}_el{configs.e_layers}_df{configs.d_ff}_ds{configs.dropout}_eb{configs.batch_size}_seed{seed}'\n",
    "\n",
    "\n",
    "    weights_path = os.path.join('./checkpoints/', setting)\n",
    "    if not os.path.exists(weights_path):\n",
    "        os.makedirs(weights_path)\n",
    "\n",
    "    train_steps = len(train_loader)\n",
    "    # Define loss function and optimizer\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=configs.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer = optimizer,\n",
    "                                                steps_per_epoch = train_steps,\n",
    "                                                pct_start = configs.pct_start,\n",
    "                                                epochs = configs.num_epochs,\n",
    "                                                max_lr = configs.learning_rate)\n",
    "    early_stopping = EarlyStopping(patience=configs.patience, verbose=True)\n",
    "    \n",
    "    return model, criterion, optimizer, scheduler, early_stopping, weights_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali(model, configs, device, val_loader, criterion):\n",
    "        total_loss = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y) in enumerate(val_loader):\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float().to(device)\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "                f_dim = -1 if configs.features == 'MS' else 0\n",
    "                outputs = outputs[:, -configs.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -configs.pred_len:, f_dim:].to(device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        model.train()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, weights_path):\n",
    "\n",
    "    for epoch in range(configs.num_epochs):\n",
    "        iter_count = 0\n",
    "        train_loss = []\n",
    "        # time_now = time.time()\n",
    "        model.train()\n",
    "        epoch_time = time.time()\n",
    "        for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            iter_count += 1\n",
    "            optimizer.zero_grad()\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "        \n",
    "            outputs = model(batch_x)\n",
    "            f_dim = -1 if configs.features == 'MS' else 0\n",
    "            outputs = outputs[:, -configs.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -configs.pred_len:, f_dim:].to(device)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # if (i + 1) % 100 == 0:\n",
    "            #     print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "            #     speed = (time.time() - time_now) / iter_count\n",
    "            #     left_time = speed * ((configs.num_epochs - epoch) * configs.train_steps - i)\n",
    "            #     print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "            #     iter_count = 0\n",
    "            #     time_now = time.time()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            #Adjust learning rate\n",
    "            lr_adjust = {epoch: scheduler.get_last_lr()[0]}\n",
    "            if epoch in lr_adjust.keys():\n",
    "                lr = lr_adjust[epoch]\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr\n",
    "                # if False: print('Updating learning rate to {}'.format(lr))\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "        train_loss = np.average(train_loss)\n",
    "        val_loss = vali(model, configs, device, val_loader, criterion) \n",
    "        \n",
    "        early_stopping(val_loss, model, weights_path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            test_loss = vali(model, configs, device, test_loader, criterion)\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "            epoch + 1, len(train_loader), train_loss, val_loss, test_loss))\n",
    "            break\n",
    "\n",
    "        print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(configs, model, loader, device):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    inputx = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "            f_dim = -1 if configs.features == 'MS' else 0\n",
    "            outputs = outputs[:, -configs.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -configs.pred_len:, f_dim:].to(device)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "            pred = outputs\n",
    "            true = batch_y\n",
    "\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "            inputx.append(batch_x.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    trues = np.concatenate(trues, axis=0)\n",
    "    inputx = np.concatenate(inputx, axis=0)\n",
    "\n",
    "    return preds, trues, inputx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_SMARD_prediction_data(path, remove_bad_columns=False):\n",
    "\n",
    "    df = pd.read_csv(path, delimiter=';', thousands='.', decimal=',', dtype={\"Datum\":str})\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df.pop(\"Datum\")+' '+df.pop(\"Anfang\"), format=\"%d.%m.%Y %H:%M\")\n",
    "    df[\"Date\"] = df[\"Date\"].dt.tz_localize(\"Europe/Berlin\", ambiguous='infer').dt.tz_convert('UTC')\n",
    "\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "        'Gesamt (Netzlast) [MWh] Originalauflösungen': 'Total Load [MWh]',\n",
    "        'Residuallast [MWh] Originalauflösungen': 'Residual Load [MWh]'\n",
    "        }\n",
    "    )\n",
    "    if remove_bad_columns==True:\n",
    "        df = df.drop(['Residual Load [MWh]'], axis=\"columns\")\n",
    "        df.pop('Ende')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_results(val_dates, test_dates, val_trues, test_trues, val_results, test_results):\n",
    "    # take dates, trues and preds\n",
    "    # create a dataframe for validation and another one for test results, \n",
    "    # the columns for each are the dates, trues and preds for each model\n",
    "    # retrieve SMARD data and merge with results dataframes\n",
    "    # concatenate both dataframes\n",
    "    all_val_results = pd.DataFrame({\n",
    "        \"Date\": pd.to_datetime(val_dates, format=\"ISO8601\"),\n",
    "        \"True Value\": val_trues\n",
    "    })\n",
    "    for i, val_pred in enumerate(val_results):\n",
    "        all_val_results[f\"Model {i+1} Forecast\"] = val_pred\n",
    "\n",
    "    for i, val_pred in enumerate(val_results):\n",
    "        all_val_results[f\"Model {i+1} Absolute Error\"] = np.abs(all_val_results[\"True Value\"] - all_val_results[f\"Model {i+1} Forecast\"])\n",
    "    \n",
    "    for i, val_pred in enumerate(val_results):\n",
    "        all_val_results[f\"Model {i+1} Absolute Percentage Error\"] = (abs(all_val_results[\"True Value\"] - all_val_results[f\"Model {i+1} Forecast\"])/all_val_results[\"True Value\"]*100)\n",
    "\n",
    "    all_test_results = pd.DataFrame({\n",
    "        \"Date\": pd.to_datetime(test_dates, format=\"ISO8601\"),\n",
    "        \"True Value\": test_trues\n",
    "    })\n",
    "\n",
    "    for i, test_pred in enumerate(test_results):\n",
    "        all_test_results[f\"Model {i+1} Forecast\"] = test_pred\n",
    "    \n",
    "    for i, test_pred in enumerate(test_results):\n",
    "        all_test_results[f\"Model {i+1} Absolute Error\"] = np.abs(all_test_results[\"True Value\"] - all_test_results[f\"Model {i+1} Forecast\"])\n",
    "    \n",
    "    for i, test_pred in enumerate(test_results):\n",
    "        all_test_results[f\"Model {i+1} Absolute Percentage Error\"] = (abs(all_test_results[\"True Value\"] - all_test_results[f\"Model {i+1} Forecast\"])/all_test_results[\"True Value\"]*100)\n",
    "    \n",
    "    display(all_val_results.describe())\n",
    "    display(all_test_results.describe())\n",
    "\n",
    "    url=\"https://raw.githubusercontent.com/koljaeger/smardcast/main/data/Prognostizierter_Stromverbrauch_\"\n",
    "\n",
    "    SMARD_prediction_df = pd.concat([read_SMARD_prediction_data(url+\"202101010000_202112312359_Viertelstunde.csv\", remove_bad_columns=True),\n",
    "                                    read_SMARD_prediction_data(url+\"202201010000_202212312359_Viertelstunde.csv\", remove_bad_columns=True),\n",
    "                                    read_SMARD_prediction_data(url+\"202301010000_202312312359_Viertelstunde.csv\", remove_bad_columns=True)])\n",
    "\n",
    "    all_val_results[\"SMARD Forecast\"] = list(SMARD_prediction_df[\"Total Load [MWh]\"][(SMARD_prediction_df[\"Date\"] >= all_val_results[\"Date\"].iloc[0]) & (all_val_results[\"Date\"].iloc[-1] >= SMARD_prediction_df[\"Date\"])])\n",
    "    all_test_results[\"SMARD Forecast\"] = list(SMARD_prediction_df[\"Total Load [MWh]\"][(SMARD_prediction_df[\"Date\"] >= all_test_results[\"Date\"].iloc[0]) & (all_test_results[\"Date\"].iloc[-1] >= SMARD_prediction_df[\"Date\"])])\n",
    "\n",
    "    results = pd.concat([all_val_results, all_test_results])\n",
    "    results[\"SMARD Absolute Error\"] = abs(results[\"True Value\"] - results[\"SMARD Forecast\"])\n",
    "\n",
    "    results[\"SMARD Absolute Percentage Error\"] = (abs(results[\"True Value\"] - results[\"SMARD Forecast\"])/results[\"True Value\"]*100)\n",
    "\n",
    "    results[\"Date\"] = pd.to_datetime(results[\"Date\"], format=\"%d.%m.%Y %H:%M\")\n",
    "    display(results.describe())\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_experiment(configs, train= True, debug=False):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data, val_data, test_data = get_datasets(configs)\n",
    "    train_loader, val_loader, test_loader = get_dataloaders(configs, train_data, val_data, test_data)\n",
    "    \n",
    "    # train a few times with different random seeds and collect the results\n",
    "    # random_seeds = [42, 1337, 987654, 202411, 7777777]\n",
    "    random_seeds = [42, 1337, 987654]\n",
    "\n",
    "    # random_seeds = [987654] #remove after testing\n",
    "\n",
    "    elapsed_times = []\n",
    "    val_dates = []\n",
    "    test_dates = []\n",
    "    val_results = []\n",
    "    test_results = []\n",
    "    first = True\n",
    "\n",
    "    for seed in random_seeds:\n",
    "        set_seed(seed)\n",
    "        \n",
    "        #create model\n",
    "        model, criterion, optimizer, scheduler, early_stopping, path = initialize_model(configs, device, train_loader, seed)\n",
    "       \n",
    "        if train:\n",
    "            #train model\n",
    "            start = time.time()\n",
    "            train_model(configs, model, train_loader, val_loader, test_loader, device, criterion, optimizer, scheduler, early_stopping, path)\n",
    "            elapsed_times.append(time.time() - start)\n",
    "        # else:\n",
    "            #load weights\n",
    "        model.load_state_dict(torch.load(os.path.join(path, 'checkpoint.pth')))\n",
    "        \n",
    "        print(path)\n",
    "\n",
    "        #test model\n",
    "        val_preds, val_trues, _ = test(configs, model, val_loader, device)\n",
    "        test_preds, test_trues, _ = test(configs, model, test_loader, device)\n",
    "        \n",
    "        #store results\n",
    "        if first:\n",
    "            val_dates = val_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            test_dates = test_data.get_timestamps().flatten()  # get timestamps for prediction sequences\n",
    "            val_trues_1_dim = val_data.inverse_transform(val_trues.reshape(-1, val_trues.shape[-1]))[:, -1]\n",
    "            test_trues_1_dim = test_data.inverse_transform(test_trues.reshape(-1, test_trues.shape[-1]))[:, -1]\n",
    "            first = False\n",
    "        val_results.append(val_data.inverse_transform(val_preds.reshape(-1, val_preds.shape[-1]))[:, -1])\n",
    "        test_results.append(test_data.inverse_transform(test_preds.reshape(-1, test_preds.shape[-1]))[:, -1])\n",
    "    \n",
    "    #Organize results\n",
    "    results = organize_results(val_dates, test_dates, val_trues_1_dim, test_trues_1_dim, val_results, test_results)\n",
    "\n",
    "    mapes = [results[col].mean() for col in results.columns if 'Model' in col and 'Absolute Percentage Error' in col]\n",
    "    print(\"MAPEs for each model: \", mapes)\n",
    "    mean = np.mean(mapes)\n",
    "    sem= stats.sem(mapes)\n",
    "    ci = stats.t.interval(0.95, len(mapes)-1, loc=mean, scale=sem)\n",
    "    print(f\"Overall MAPE 95% confidence interval: {ci}\")\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Number of trainable parameters: \", params)\n",
    "\n",
    "    all_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"Total number of parameters: \", all_params)\n",
    "\n",
    "    return ci, results, elapsed_times, params, all_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_names = [\n",
    "    \"ettm_configs\", #0\n",
    "    \"electricity_configs\", #1\n",
    "    \"ettm_configs_multivariate\", #2\n",
    "    \"electricity_configs_multivariate\", #3\n",
    "    \"not_augmented\", #4\n",
    "    \"32_patches_electricity_configs\", #5\n",
    "    \"64_patches_electricity_configs\", #6\n",
    "    \"one_head_electricity_configs\", #7\n",
    "    \"eight_heads_electricity_configs\", #8\n",
    "    \"32_heads_electricity_configs\", #9\n",
    "    \"train_set_not_shuffled_electricity_configs\", #10\n",
    "    \"patch_len_2_stride=1_electricity_configs\", #11\n",
    "    \"patch_len_1,_stride_1_electricity_configs\", #12\n",
    "    \"32_dims_electricity_configs\", #13\n",
    "    \"32_patches_electricity_configs_Multivariate\", #14\n",
    "    \"16_patches_electricity_configs\" #15\n",
    "]\n",
    "\n",
    "experiment_configs = [\n",
    "    get_configs(name=experiment_names[0]),\n",
    "    get_configs(name=experiment_names[1], enc_in=321, pct_start = 0.2, patience=10, batch_size=32),\n",
    "    get_configs(name=experiment_names[2], features='M'),\n",
    "    get_configs(name=experiment_names[3], enc_in=321, pct_start = 0.2, patience=10, batch_size=32, features='M'),\n",
    "    get_configs(name=experiment_names[4], window_split=96),\n",
    "    get_configs(name=experiment_names[5], enc_in=321, pct_start = 0.2, patience=10, batch_size=32, patch_len=72, stride=20),\n",
    "    get_configs(name=experiment_names[6], enc_in=321, pct_start = 0.2, patience=10, batch_size=32, patch_len=52, stride=10),\n",
    "    get_configs(name=experiment_names[7], n_heads = 1, enc_in=321, pct_start = 0.2, patience=10, batch_size=32),\n",
    "    get_configs(name=experiment_names[8], n_heads = 8, enc_in=321, pct_start = 0.2, patience=10, batch_size=32),\n",
    "    get_configs(name=experiment_names[9], n_heads = 32, enc_in=321, pct_start = 0.2, patience=10, batch_size=32),\n",
    "    get_configs(name=experiment_names[10], shuffle_train=False, enc_in=321, pct_start = 0.2, patience=10, batch_size=32),\n",
    "    get_configs(name=experiment_names[11], enc_in=321, pct_start = 0.2, patience=10, batch_size=32, patch_len=2, stride=1),\n",
    "    get_configs(name=experiment_names[12], enc_in=321, pct_start = 0.2, patience=10, batch_size=32, patch_len=1, stride=1),\n",
    "    get_configs(name=experiment_names[13], d_model=32, enc_in=321, pct_start = 0.2, patience=10, batch_size=32),\n",
    "    get_configs(name=experiment_names[14], enc_in=321, pct_start = 0.2, patience=10, batch_size=32, patch_len=72, stride=20, features='M'),\n",
    "    get_configs(name=experiment_names[15], enc_in=321, pct_start = 0.2, patience=10, patch_len=112, stride=40)\n",
    "]\n",
    "\n",
    "elapsed_np_names = [\n",
    "    'elapsed_default.npy',\n",
    "    'e_elapsed.npy',\n",
    "    'elapsed_times_default_M.npy',\n",
    "    'elapsed_times_electricity_M.npy',\n",
    "    'elapsed_na.npy',\n",
    "    'elapsed_32.npy',\n",
    "    'elapsed_64.npy',\n",
    "    'elapsed_1_head.npy',\n",
    "    'elapsed_8_heads.npy',\n",
    "    'elapsed_32_heads.npy',\n",
    "    'elapsed_no_shuffle.npy',\n",
    "    'elapsed_l2_s1.npy',\n",
    "    'elapsed_l1_s1.npy',\n",
    "    'elapsed_model_dim_32.npy',\n",
    "    'eelapsed_32_patches_M.npy',\n",
    "    'elapsed_16_patches_S.npy'\n",
    "]\n",
    "\n",
    "cis = []\n",
    "results = []\n",
    "elapsed_times = []\n",
    "num_trainable_params = []\n",
    "num_all_params = []\n",
    "\n",
    "train = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_experiment_index = np.load('last_experiment_index.npy')\n",
    "# if last_experiment_index +1 >= len(experiment_configs):\n",
    "#     train = False\n",
    "#     print(\"All experiments have already been run. Loading results.\")\n",
    "\n",
    "# print(last_experiment_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, experiment in enumerate(experiment_names):\n",
    "    print(f\"Starting experiment {i}: {experiment_names[i]}\")\n",
    "    # if i > last_experiment_index:\n",
    "    ci, result, elapsed, params, all_params = do_experiment(configs = experiment_configs[i], train=train)\n",
    "\n",
    "    if train:\n",
    "        np.save(elapsed_np_names[i], np.array(elapsed))\n",
    "    else:\n",
    "        elapsed = np.load(elapsed_np_names[i], allow_pickle=True)\n",
    "\n",
    "    cis.append(ci)\n",
    "    results.append(result)\n",
    "    elapsed_times.append(elapsed)\n",
    "    num_trainable_params.append(params)\n",
    "    num_all_params.append(all_params)\n",
    "\n",
    "        # np.save('last_experiment_index.npy', np.array(i))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 3; #change this to run a specific experiment\n",
    "# ci, result, elapsed, params, all_params = do_experiment(configs = experiment_configs[i], train=train)\n",
    "\n",
    "# if train:\n",
    "#     np.save(elapsed_np_names[i], np.array(elapsed))\n",
    "# else:\n",
    "#     elapsed = np.load(elapsed_np_names[i], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elapsed in elapsed_times:\n",
    "    print(elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patchtst_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
